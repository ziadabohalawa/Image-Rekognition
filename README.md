# ğŸ¯ Object-Detection Demo â€“ Flask Ã— API Gateway Ã— Lambda Ã— Rekognition

Type an S3 image key â†’ the app calls **Amazon Rekognition** through a lightweight **Lambda** endpoint â†’ returns an annotated picture plus JSON labels & confidences.  
Runs happily on the smallest CPU EC2 instance.

---

## ğŸ›ï¸ High-Level Architecture

Browser EC2 (Flask) API Gateway Lambda Rekognition
â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Upload â”‚1. â”‚POST /{key} â”‚2. â”‚proxy JSON â”‚3. â”‚detect_labelsâ”‚â”€â”€â–º â”‚ ML model â”‚
form â””â”€â”€â–º â”‚downloads imgâ”‚â”€â”€â–º â”‚to Lambda â”‚â”€â”€â–º â”‚return JSON â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–² â”‚draw boxes â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚HTML result â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€ 4. response (img + JSON) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

S3 bucket
â”œâ”€ images/ (source jpg/png)
â””â”€ (bucket is private)

yaml
Copy
Edit

---

## ğŸ§° Tech Stack

| Layer | Technology |
|-------|------------|
| UI & Backend | **Flask 2** (Python 3.10) |
| Image Ops    | Pillow (PIL) |
| Serverless   | **AWS Lambda** (Python run-time) |
| API Gateway  | HTTP API â€“ forwards to Lambda |
| ML Service   | **Amazon Rekognition** (`detect_labels`) |
| Storage      | **Amazon S3** (`images/â€¦`) |
| Compute node | **EC2 t3.micro** (or larger) |

---

## ğŸ“‹ Prerequisites

| What | Minimum setup |
|------|---------------|
| **S3 bucket** | `<YOUR-BUCKET>/images/*.jpg`  |
| **Lambda**    | Paste `lambda_handler.py` code & give it **`rekognition:DetectLabels`** |
| **API Gateway** | HTTP API â†’ integrate Lambda â†’ public invoke URL `<APIâ€URL>` |
| **EC2 security group** | Inbound TCP 22 (SSH) & 5000 (Flask) |
| **IAM role on EC2** | `s3:GetObject` (read-only) on the bucket |

---

## ğŸš€ Step-by-Step Setup

### 1  SSH & clone repo

```
ssh -i my-key.pem ubuntu@<EC2-IP>
git clone https://github.com/<your-user>/rekognition-demo.git
cd rekognition-demo
python3 -m venv venv && source venv/bin/activate
```
### 2 Install Python deps
```
pip install -r requirements.txt   # Flask, boto3, Pillow, requests
```
### 3 Run Flask app
```
python app.py \
    --bucket  <YOUR-BUCKET> \
    --api-url <API-URL> \
    --debug
# Flask binds to 0.0.0.0:5000
```
4 Open in browser
```http://<EC2-PUBLIC-IP>:5000```
Type an image key, e.g. images/dog.jpg â†’ see bounding boxes & JSON.

ğŸ—‚ Project Layout
```
rekognition-demo/
â”œâ”€ app.py              # Flask factory + drawing logic
â”œâ”€ lambda_handler.py   # (deploy inside Lambda)
â”œâ”€ templates/
â”‚   â””â”€ index.html      # form + result view
â”œâ”€ static/output.jpg   # generated file (runtime)
â”œâ”€ requirements.txt
â””â”€ README.md
```
ğŸ™ Acknowledgements
Amazon Rekognition â€“ fully managed vision APIs

Flask (Â© Pallets) â€“ BSD-licensed micro-framework

Pillow â€“ the friendly PIL fork

